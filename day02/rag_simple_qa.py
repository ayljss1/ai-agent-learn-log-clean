# rag_simple_qa.py
import faiss
import requests
from sentence_transformers import SentenceTransformer

# 1. åŠ è½½æ®µè½
with open("data/sample.txt", "r", encoding="utf-8") as f:
    text = f.read()
paragraphs = [p.strip() for p in text.split("ã€‚") if p.strip()]

# 2. åŠ è½½å‘é‡åº“
index = faiss.read_index("day02/faiss_index.idx")

# 3. åŠ è½½åµŒå…¥æ¨¡å‹
model = SentenceTransformer("all-MiniLM-L6-v2")

# 4. ç”¨æˆ·è¾“å…¥é—®é¢˜
question = input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
query_vec = model.encode([question])

# 5. å‘é‡æœç´¢
top_k = 3
D, I = index.search(query_vec, top_k)

# 6. æ„é€ ä¸Šä¸‹æ–‡
retrieved_context = "\n".join([paragraphs[idx] for idx in I[0]])

# 7. æ‹¼æ¥ prompt
prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£é—®ç­”åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ã€æ–‡æ¡£å†…å®¹ã€‘
{retrieved_context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

ã€å›ç­”ã€‘
"""
print(prompt)
# 8. è°ƒç”¨æœ¬åœ° LLM (Ollama)
response = requests.post(
    "http://localhost:11434/api/generate",
    json={"model": "llama3", 
          "prompt": prompt, 
          "stream": False
    }
)

answer = response.json()["response"]
print("\nğŸ¤– å›ç­”ï¼š\n", answer)
